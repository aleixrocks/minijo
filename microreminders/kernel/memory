VIRTUAL MEMORY
 - Each process belives it has its entire 32-bit or 64-bit address space for
   itself. However, this "virtual addresses" are mapped to physical pages. The
   mapping is stored in the page-table. Each process has its own page table.
   Threads of the same process share the same page table. When a process
   switches to another process (i.e. there is a change in the address space),
   the page tables are switched and the TLBs (see below) flushed. Note that
   switching to a kernel thread does not generally involve switching to another
   page table since the kernel address space, in which all kernel threads run,
   is defined in every page table structure. For user processes, the switch to
   their own page table is performed by the architecture-specific routine
   switch_mm().
 - The page table and TLB (see below) stores the addresses of pages, which are
   chunks of memory (usually 4KiB).
 - The format, location of the page table plus the page size if hardware
   dependent. This is so because the translation from virtual adresses (issued
   by a process running in a processor) to physical addresses is handled by
   the hardware, namely, the Translation Lookaside Buffer (inside the
   processor's pipeline). The TLB is just a cache that keeps track of the last
   used pages virtual adresses and its correspoding tranlation to physical
   addresses. When the TLB does not contain the translation, a TLB-miss happens
   and the pipeline stalls until the physical address is read from the
   in-memory process-dependent page table. If the requested page is not
   loaded in main memory, a "page fault" occur and the processor jumps to
   the page fault handler which is in charge of loading the page from disk into
   main memory and to update the corresponding page-table entry (and the TLB
   entry as well). 
 - Page tables have multiple levels to reduce its size. Each process does not
   has an array for each possible page but multiple page tables, each
   corresponding to a different level in the page table. Each page entry either
   contains an address to another page table or a physical page address.
 - The Linux Kernel stores the location of the page global directory (which is
   the first level of the page table of the process) in the mm structure of
   each task_struct.
 - The address space is divided in two (this is named flat address space). On a
   32 bit machine, for example, the lower 3GiB are reserver for user-space
   processes and the upper 1GiB is for kernel-only use. This means that (on
   such systems) a user-space process can only use 3GiB of memory and the
   kernel 1GiB of memory because they cannot address more. The reason for such
   limitation is performance.  It could be possible to switch the address space
   every time a mode switch (user to kernel or kernel to user spaces) is done,
   but this would require to also flush the TLB and even the cache on some
   architectures. Think that you only have 32 bits of addresses, that you need
   to differentiate user space from kernel space to protect kernel space and
   that you cannot change address spaces when changing form user to kernel or
   kernel to user because of performance. Then, you are simply limited.
 - The term HIGH MEMORY and LOW MEMORY arise from this fact. Low memory is
   physical memory that is permanently mapped to virtual memory (VM), while
   high memory is not. Roughly, almost all Linux kernel memory is low memory
   while user-level memory is high memory. More precisely, the Linux Kernel
   splits virtual memory into kernel and user space. When a context switch
   between processes occur, the address space of the current process changes
   for another one. However, the Kernel mapping does not change (its pages are
   permanently mapped into the system's page table), so it is known as low
   memory (most of it). Not all the kernel space memory is low memory because
   the kernel needs to keep some addresses to map IO devices (such as DMA
   devices), a region for vmalloc() to allocate large portions of virtually
   contiguous memory (not necessarily physically contiguous) and a region to map user space pages.  Comparatively,
   kmalloc() guarantees that the pages are both physically and virtually
   contiguous, while vmalloc only guarantees that pages are virtually
   contiguous. Finding large portions of physically contiguous memory might be
   difficult, and this is why vmalloc exist.  In fact, vmalloc is similar to
   how the malloc syscall works.
   
   *** verify!!
   Every
   kernel process can access directly the current user thread memory, but if it
   wants to access memory from any other user thread than the current one, it
   has to temporarly map its memory into a special area in the kernel space and
   unmapp it after it has finished using it.  This is done with the kmap()
   kernel function

   ***

 - Another high/low mem definition: The term HIGH MEMORY and LOW MEMORY arise
   from this fact. High memory (highmem) is used when the size of physical
   memory approaches or exceeds the maximum size of virtual memory. At that
   point it becomes impossible for the kernel to keep all of the available
   physical memory mapped at all times.  This means the kernel needs to start
   using temporary mappings of the pieces of physical memory that it wants to
   access. The part of (physical) memory not covered by a permanent mapping is
   what we refer to as 'highmem'.  There are various architecture dependent
   constraints on where exactly that border lies.  This means that the kernel
   can at most map 1GiB of physical memory at any one time, but because we need
   virtual address space for other things - including temporary maps to access
   the rest of the physical memory - the actual direct map will typically be
   less (usually around ~896MiB). Lets say a system with configuration as
   follows, 2GB of physical RAM, 40 MB of physical io address space, 240 MB of
   vmalloc address space, 32 MB for persistent kernel map The maximum RAM which
   can be mapped as low mem = 1GB - (40 MB + 240 MB + 32MB) = 712MB. The Rest
   of RAM (1GB - 712MB) will fall as HIGH_MEM.  Other architectures that have
   mm context tagged TLBs can have separate kernel and user maps.  Some
   hardware (like some ARMs), however, have limited virtual space when they use
   mm context tags.
 - Sometimes, the kernel needs to access user-space highmem, such as when it has
   to copy to/from user parameters on a system call or when it has to zero a
   page. To access "high memory" the kernel can temporarily map user-space
   pages into kernel space pages with the kmap() and kmap_atomic() functions.
   Once the kernel is done which such pages, it has de unmap them with kunmap()
   and kumap_atomic().

PAGES
 - struct page -> main page struct at <linux/mm_types.h>. An instance of
   this structure is created for every page on the system.
 - The data structure’s goal is to describe physical memory, not the data
   contained therein. Even if the data contained in the page continues to
   exist, it might not always be associ- ated with the same page structure
   because of swapping and so on.
 - The kernel uses this structure to keep track of all the pages in the system,
   because the kernel needs to know whether a page is free (that is, if the
   page is not allocated). If a page is not free, the kernel needs to know who
   owns the page. Possible owners include user-space processes, dynamically
   allocated kernel data, static kernel code, the page cache, and so on.
 - page_count() -> returns zero to indicate free page, positivte otherwise
 - Alloc pages
     - struct page * alloc_pages(gfp_t gfp_mask, unsigned int order) ->
       allocates 2^order contiguous physical pages and returns a pointer to the
       first page's page.
     - unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order) -> it
       works the same as alloc_pages(), except that it directly returns the
       logical address of the first requested page. Because the pages are
       contiguous, the other pages simply follow from the first.
     - void * page_address(struct page *page) -> return logical address where
       the given physical page resides.
     - struct page * alloc_page(gfp_t gfp_mask); unsigned long
       __get_free_page(gfp_t gfp_mask) -> the same as the others but only for
       one page.
     - unsigned long get_zeroed_page(unsigned int gfp_mask) -> Works he same as
       __get_free_page(), except that the allocated page is zero-filled.
 - Free pages
     - You must be careful to free only pages you allocate. Passing the wrong
       struct page or address, or the incorrect order , can result in
       corruption. Remember, the kernel trusts itself. Unlike with user-space,
       the kernel will happily hang itself if you ask it.
     - void __free_pages(struct page *page, unsigned int order)
     - void free_pages(unsigned long addr, unsigned int order)
     - void free_page(unsigned long addr)

PAGE FAULT
 - major page fault: a page was not in main memory
 - minor page fault: a page was in memory but it was not allocated for the
   process asking for it. The kernel responds sharing the page.
 - ps -eo min_flt, maj_flt,cmd -> list minor and major page faults for each
   process on the system.
 - /usr/bin/time -v <command> -> reports the number of major and minor page
   faults for the execution of command.

ZONES
 - Why memory zones?
    - Some hardware devices can perform DMA (direct memory access) to only
      certain memory addresses.
    - Some architectures can physically addressing larger amounts of memory
      than they can virtually address. Consequently, some memory is not
      permanently mapped into the kernel address space.
 - Types of zones
    - ZONE_DMA —This zone contains pages that can undergo DMA.
    - ZONE_DMA32 —Like ZOME_DMA , this zone contains pages that can undergo
      DMA.  Unlike ZONE_DMA , these pages are accessible only by 32-bit
      devices. On some
      archi- tectures, this zone is a larger subset of memory.
    - ZONE_NORMAL —This zone contains normal, regularly mapped, pages.
    - ZONE_HIGHMEM —This zone contains “high memory,” which are pages not
      permanently mapped into the kernel’s address space.
 - Sizes of zones on x86-32
    - Zone Description Physical Memory
    - ZONE_DMA DMA-able pages < 16MB
    - ZONE_NORMAL Normally addressable pages 16–896MB
    - ZONE_HIGHMEM Dynamically mapped pages > 896MB
 - struct zone is defined in <linux/mmzone.h>
 - For example, a 64-bit architecture such as Intel’s x86-64 can fully map and
   handle 64-bits of memory.Thus, x86-64 has no ZONE_HIGHMEM and all physical
   memory is contained within ZONE_DMA and ZONE_NORMAL .
 - Allocations cannot cross zone boundaries.


KMALLOC AND FRIENDS
 - used to allocate byte-size chunks of memory. Defined at <linux/slab.h>
 - kmalloc guarantees that the pages are physically and virtually contiguous.
 - kmalloc() may allocate more than you asked, although you have no way of
   knowing how much more! Because at its heart the kernel allocator is
   page-based, some allocations may be rounded up to fit within the available
   memory. The kernel never returns less memory than requested. If the kernel
   is unable to find at least the requested amount, the allocation fails and
   the function returns NULL .
 - The kmalloc flags are defined in <linux/gfp.h> (GFP stands for "Get Free
   Pages"). There are three types of flags: action modifiers (how the kernel
   allocate the memory, for instance, we don't want to sleep in interrupt
   context), zone modifiers (which zone it should be allocated) and types (a
   combinatino of action and zone modifiers). Some tipic type flags are:
    - GFP_KERNEL: This is a normal allocation and might block. This is the
      flag to use in process context code when it is safe to sleep. The
      kernel will do whatever it has to do to obtain the memory requested by
      the caller. This flag should be your default choice.
    - GFP_ATOMIC: The allocation is high priority and must not sleep. This is
      the flag to use in interrupt handlers, in bottom halves, while holding
      a spinlock, and in other situations where you cannot sleep.
    - GFP_USER: This is a normal allocation and might block. This flag is
      used to allocate memory for user-space processes.
    - GFP_DMA: This is an allocation from ZONE_DMA . Device drivers that need
      DMA-able memory use this flag, usually in combination with one of the
      preceding flags.
 - If kmalloc cannot sleep, the allocation is restrictive in the memory it can
   obtain for the caller. if no sufficient sized continguous chunk of memory
   is available, the kernel is not likel to free memory.
 - If kmalloc can sleep, then i can swap inactive pages to disk, flush dirty
   pages to disk, and so on.
 - kfree(const void *ptr) -> deallocate memory previously allocated with kmalloc
    - kfree(NULL) -> it is safe 
 - vmalloc() -> It allocates memory that is only virtually continguous and not
   necessarily physically continguous. It does this by allocating potentially
   noncontiguous chunks of physical memory and "fixing up" the page tables to
   map the memory into a contiguous chunk of the logical address space. It is
   declared at <linux/vmalloc.h> and defined in mm/vmalloc.c.
    - Any regions of memory that hardware devices work with must exist as a
      physically contiguous block and not merely a virtually contiguous one.
    - For normal proccesses, is fine using memory that is only virtually
      contiguous. In your programming, you never know the difference. All
      memory appears to the kernel as logically contiguous.
    - vfree(const void *addr) -> free memory. It can sleep.
 - kmalloc is used more often than vmalloc even when non-continuous physical
   pages are needed. This is because kmalloc is more efficient than vmalloc.
   vmalloc refactors the page table and results in much greater TLB trashing.

SLAB ALLOCATOR
 - The kernel maintains an allocated pool of memory that is used to grab the
   neccessary data from there when a memory allocation request arrive. This way
   is not necessary to actually allocate data every time is requested.
 - The slab allocator is composed of caches. Each cache stores a particular
   type of object, such as task_struct. Then, each cache is divided into
   multiple slabs. A slab is a set of pysically contiguous pages, typically one.
 - Each slab can be in one of the following states: empty, partial or full.
   When allocating objects, firsts go the partial slabs, then empty. If there
   are no empty slabs, then another one is allocated.
 - Structure:
    - The cached objects follows the following convention: For an inode, we have
      inode_cachep cache.
    - kmem_cache struct represents a cache. it has tree slab objects for full, 
      empty and partial.
    - Each struct slab contains a list of pages.
