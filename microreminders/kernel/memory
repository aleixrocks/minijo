VIRTUAL MEMORY
 - Each process belives it has its entire 32-bit or 64-bit address space for
   itself. However, this "virtual addresses" are mapped to physical pages. The
   mapping is stored in the page-table. Each process has its own page table.
   Threads of the same process share the same page table. When a process
   switches to another process (i.e. there is a change in the address space),
   the page tables are switched and the TLBs (see below) flushed. Note that
   switching to a kernel thread does not generally involve switching to another
   page table since the kernel address space, in which all kernel threads run,
   is defined in every page table structure. For user processes, the switch to
   their own page table is performed by the architecture-specific routine
   switch_mm().
 - The page table and TLB (see below) stores the addresses of pages, which are
   chunks of memory (usually 4KiB).
 - The format, location of the page table plus the page size if hardware
   dependent. This is so because the translation from virtual adresses (issued
   by a process running in a processor) to physical addresses is handled by
   the hardware, namely, the Translation Lookaside Buffer (inside the
   processor's pipeline). The TLB is just a cache that keeps track of the last
   used pages virtual adresses and its correspoding tranlation to physical
   addresses. When the TLB does not contain the translation, a TLB-miss happens
   and the pipeline stalls until the physical address is read from the
   in-memory process-dependent page table. If the requested page is not
   loaded in main memory, a "page fault" occur and the processor jumps to
   the page fault handler which is in charge of loading the page from disk into
   main memory and to update the corresponding page-table entry (and the TLB
   entry as well). 
 - Page tables have multiple levels to reduce its size. Each process does not
   has an array for each possible page but multiple page tables, each
   corresponding to a different level in the page table. Each page entry either
   contains an address to another page table or a physical page address.
 - The Linux Kernel stores the location of the page global directory (which is
   the first level of the page table of the process) in the mm structure of
   each task_struct.
 - The address space is divided in two (this is named flat address space). On a
   32 bit machine, for example, the lower 3GiB are reserver for user-space
   processes and the upper 1GiB is for kernel-only use. This means that (on
   such systems) a user-space process can only use 3GiB of memory and the
   kernel 1GiB of memory because they cannot address more. The reason for such
   limitation is performance.  It could be possible to switch the address space
   every time a mode switch (user to kernel or kernel to user spaces) is done,
   but this would require to also flush the TLB and even the cache on some
   architectures. Think that you only have 32 bits of addresses, that you need
   to differentiate user space from kernel space to protect kernel space and
   that you cannot change address spaces when changing form user to kernel or
   kernel to user because of performance. Then, you are simply limited.
 - The term HIGH MEMORY and LOW MEMORY arise from this fact. Low memory is
   physical memory that is permanently mapped to virtual memory (VM), while
   high memory is not. Roughly, almost all Linux kernel memory is low memory
   while user-level memory is high memory. More precisely, the Linux Kernel
   splits virtual memory into kernel and user space. When a context switch
   between processes occur, the address space of the current process changes
   for another one. However, the Kernel mapping does not change (its pages are
   permanently mapped into the system's page table), so it is known as low
   memory (most of it). Not all the kernel space memory is low memory because
   the kernel needs to keep some addresses to map IO devices (such as DMA
   devices), a region for vmalloc() to allocate large portions of virtually
   contiguous memory (not necessarily physically contiguous) and a region to map user space pages.  Comparatively,
   kmalloc() guarantees that the pages are both physically and virtually
   contiguous, while vmalloc only guarantees that pages are virtually
   contiguous. Finding large portions of physically contiguous memory might be
   difficult, and this is why vmalloc exist.  In fact, vmalloc is similar to
   how the malloc syscall works.
   
   *** verify!!
   Every
   kernel process can access directly the current user thread memory, but if it
   wants to access memory from any other user thread than the current one, it
   has to temporarly map its memory into a special area in the kernel space and
   unmapp it after it has finished using it.  This is done with the kmap()
   kernel function

   ***

 - Another high/low mem definition: The term HIGH MEMORY and LOW MEMORY arise
   from this fact. High memory (highmem) is used when the size of physical
   memory approaches or exceeds the maximum size of virtual memory. At that
   point it becomes impossible for the kernel to keep all of the available
   physical memory mapped at all times.  This means the kernel needs to start
   using temporary mappings of the pieces of physical memory that it wants to
   access. The part of (physical) memory not covered by a permanent mapping is
   what we refer to as 'highmem'.  There are various architecture dependent
   constraints on where exactly that border lies.  This means that the kernel
   can at most map 1GiB of physical memory at any one time, but because we need
   virtual address space for other things - including temporary maps to access
   the rest of the physical memory - the actual direct map will typically be
   less (usually around ~896MiB). Lets say a system with configuration as
   follows, 2GB of physical RAM, 40 MB of physical io address space, 240 MB of
   vmalloc address space, 32 MB for persistent kernel map The maximum RAM which
   can be mapped as low mem = 1GB - (40 MB + 240 MB + 32MB) = 712MB. The Rest
   of RAM (1GB - 712MB) will fall as HIGH_MEM.  Other architectures that have
   mm context tagged TLBs can have separate kernel and user maps.  Some
   hardware (like some ARMs), however, have limited virtual space when they use
   mm context tags.
 - Sometimes, the kernel needs to access user-space highmem, such as when it has
   to copy to/from user parameters on a system call or when it has to zero a
   page. To access "high memory" the kernel can temporarily map user-space
   pages into kernel space pages with the kmap() and kmap_atomic() functions.
   Once the kernel is done which such pages, it has de unmap them with kunmap()
   and kumap_atomic().

PAGES
 - struct page -> main page struct at <linux/mm_types.h>. An instance of
   this structure is created for every page on the system.
 - The data structure’s goal is to describe physical memory, not the data
   contained therein. Even if the data contained in the page continues to
   exist, it might not always be associ- ated with the same page structure
   because of swapping and so on.
 - The kernel uses this structure to keep track of all the pages in the system,
   because the kernel needs to know whether a page is free (that is, if the
   page is not allocated). If a page is not free, the kernel needs to know who
   owns the page. Possible owners include user-space processes, dynamically
   allocated kernel data, static kernel code, the page cache, and so on.
 - page_count() -> returns zero to indicate free page, positivte otherwise
 - Alloc pages
     - struct page * alloc_pages(gfp_t gfp_mask, unsigned int order) ->
       allocates 2^order contiguous physical pages and returns a pointer to the
       first page's page.
     - unsigned long __get_free_pages(gfp_t gfp_mask, unsigned int order) -> it
       works the same as alloc_pages(), except that it directly returns the
       logical address of the first requested page. Because the pages are
       contiguous, the other pages simply follow from the first.
     - void * page_address(struct page *page) -> return logical address where
       the given physical page resides.
     - struct page * alloc_page(gfp_t gfp_mask); unsigned long
       __get_free_page(gfp_t gfp_mask) -> the same as the others but only for
       one page.
     - unsigned long get_zeroed_page(unsigned int gfp_mask) -> Works he same as
       __get_free_page(), except that the allocated page is zero-filled.
 - Free pages
     - You must be careful to free only pages you allocate. Passing the wrong
       struct page or address, or the incorrect order , can result in
       corruption. Remember, the kernel trusts itself. Unlike with user-space,
       the kernel will happily hang itself if you ask it.
     - void __free_pages(struct page *page, unsigned int order)
     - void free_pages(unsigned long addr, unsigned int order)
     - void free_page(unsigned long addr)

PAGE FAULT
 - major page fault: a page was not in main memory
 - minor page fault: a page was in memory but it was not allocated for the
   process asking for it. The kernel responds sharing the page.
 - ps -eo min_flt, maj_flt,cmd -> list minor and major page faults for each
   process on the system.
 - /usr/bin/time -v <command> -> reports the number of major and minor page
   faults for the execution of command.

ZONES
 - Why memory zones?
    - Some hardware devices can perform DMA (direct memory access) to only
      certain memory addresses.
    - Some architectures can physically addressing larger amounts of memory
      than they can virtually address. Consequently, some memory is not
      permanently mapped into the kernel address space.
 - Types of zones
    - ZONE_DMA —This zone contains pages that can undergo DMA.
    - ZONE_DMA32 —Like ZOME_DMA , this zone contains pages that can undergo
      DMA.  Unlike ZONE_DMA , these pages are accessible only by 32-bit
      devices. On some
      archi- tectures, this zone is a larger subset of memory.
    - ZONE_NORMAL —This zone contains normal, regularly mapped, pages.
    - ZONE_HIGHMEM —This zone contains “high memory,” which are pages not
      permanently mapped into the kernel’s address space.
 - Sizes of zones on x86-32
    - Zone Description Physical Memory
    - ZONE_DMA DMA-able pages < 16MB
    - ZONE_NORMAL Normally addressable pages 16–896MB
    - ZONE_HIGHMEM Dynamically mapped pages > 896MB
 - struct zone is defined in <linux/mmzone.h>
 - For example, a 64-bit architecture such as Intel’s x86-64 can fully map and
   handle 64-bits of memory.Thus, x86-64 has no ZONE_HIGHMEM and all physical
   memory is contained within ZONE_DMA and ZONE_NORMAL .
 - Allocations cannot cross zone boundaries.


KMALLOC AND FRIENDS
 - used to allocate byte-size chunks of memory. Defined at <linux/slab.h>
 - kmalloc guarantees that the pages are physically and virtually contiguous.
 - kmalloc() may allocate more than you asked, although you have no way of
   knowing how much more! Because at its heart the kernel allocator is
   page-based, some allocations may be rounded up to fit within the available
   memory. The kernel never returns less memory than requested. If the kernel
   is unable to find at least the requested amount, the allocation fails and
   the function returns NULL .
 - The kmalloc flags are defined in <linux/gfp.h> (GFP stands for "Get Free
   Pages"). There are three types of flags: action modifiers (how the kernel
   allocate the memory, for instance, we don't want to sleep in interrupt
   context), zone modifiers (which zone it should be allocated) and types (a
   combinatino of action and zone modifiers). Some tipic type flags are:
    - GFP_KERNEL: This is a normal allocation and might block. This is the
      flag to use in process context code when it is safe to sleep. The
      kernel will do whatever it has to do to obtain the memory requested by
      the caller. This flag should be your default choice.
    - GFP_ATOMIC: The allocation is high priority and must not sleep. This is
      the flag to use in interrupt handlers, in bottom halves, while holding
      a spinlock, and in other situations where you cannot sleep.
    - GFP_USER: This is a normal allocation and might block. This flag is
      used to allocate memory for user-space processes.
    - GFP_DMA: This is an allocation from ZONE_DMA . Device drivers that need
      DMA-able memory use this flag, usually in combination with one of the
      preceding flags.
 - If kmalloc cannot sleep, the allocation is restrictive in the memory it can
   obtain for the caller. if no sufficient sized continguous chunk of memory
   is available, the kernel is not likel to free memory.
 - If kmalloc can sleep, then i can swap inactive pages to disk, flush dirty
   pages to disk, and so on.
 - kfree(const void *ptr) -> deallocate memory previously allocated with kmalloc
    - kfree(NULL) -> it is safe 
 - vmalloc() -> It allocates memory that is only virtually continguous and not
   necessarily physically continguous. It does this by allocating potentially
   noncontiguous chunks of physical memory and "fixing up" the page tables to
   map the memory into a contiguous chunk of the logical address space. It is
   declared at <linux/vmalloc.h> and defined in mm/vmalloc.c.
    - Any regions of memory that hardware devices work with must exist as a
      physically contiguous block and not merely a virtually contiguous one.
    - For normal proccesses, is fine using memory that is only virtually
      contiguous. In your programming, you never know the difference. All
      memory appears to the kernel as logically contiguous.
    - vfree(const void *addr) -> free memory. It can sleep.
 - kmalloc is used more often than vmalloc even when non-continuous physical
   pages are needed. This is because kmalloc is more efficient than vmalloc.
   vmalloc refactors the page table and results in much greater TLB trashing.

SLAB ALLOCATOR
 - The kernel maintains an allocated pool of memory that is used to grab the
   neccessary data from there when a memory allocation request arrive. This way
   is not necessary to actually allocate data every time is requested.
 - The slab allocator is composed of caches. Each cache stores a particular
   type of object, such as task_struct. Then, each cache is divided into
   multiple slabs. A slab is a set of pysically contiguous pages, typically one.
 - Each slab can be in one of the following states: empty, partial or full.
   When allocating objects, firsts go the partial slabs, then empty. If there
   are no empty slabs, then another one is allocated.
 - Structure:
    - The cached objects follows the following convention: For an inode, we have
      inode_cachep cache.
    - kmem_cache struct represents a cache. it has tree slab objects for full, 
      empty and partial.
    - Each struct slab contains a list of pages.
 - From user-space, the "slabtop" command reports real time usage of the slab
   allocator.

PAGE CACHE
 - The address_space struct is a representation of a mapped region in the page
   cache. This is different than the vm_area_struct. The same region of a file
   can have 10 instances of vm_area_struct if 5 processes mmap() it twice each.
   However, only once address_space struct exist for the region mapped. Follows
   a description of some important fields:
     - i_mmap: points to all vm_area_struct of this region (one-to-n mapping)
     - host: points to the associated inode if it exists (for files) or  NULL
       otherwise (for instance swapper)
     - a_ops: points to the address_space operations table (i.e. its methods
       to write or read the cache)
     - page_tree_root: radix tree (binary tree) of all pages associated with
       this address_space. (whenever a data access is done, the kernel
       searches this tree to find the page where the data might or might not be)
 - Pages in the page cache track individual disk blocks:
 - Disk blocks are made of 512 bytes. This is the minimum that can be read or
   written from a hard drive. A page can hold 4096/512=8 blocks.
 - Buffer is the in-memory representation of a single physical disk block.
   Buffers describe the mapping of a block onto a page, which is in the page
   cache.
 - Blocks are read with the bread() function to perform a low level read.
 - A gang of threads named "flusher threads" are responsible to flush dirty
   pages to disk.
     - Pages are flushed in the following conditions:
         - When free memory drops below /proc/sys/vm/dirty_background_ratio. In
           this case, the threads execute the "bdi_writeback_all()" function.
           Next write operation do not block yet, they are still done
           asynchronously (writes syscalls return after the data has been
           written to the page cache, not the disk).
         - When the free memory drops below /proc/sys/vm/dirty_ratio number
           of pages, threads issuing write operations will itself block and wait
           until enough pages from the page cache are backed up to disk.
         - After certain period of time, flusher threads are waken up regularly
           to flush pages older than /proc/sys/vm/diry_expire_centisecs. In
           this case, threads execute "wb_writeback()" function. The threads
           timer is set at /proc/sys/vm/dirty_writeback_centisecs.
         - When a user process calls sync or fsync syscalls.
     - All files associated with /proc/sys/vm are documented in
       Documentation/sysctl/vm.txt
     - The kernel calls "wakeup_flusher_threads()" to wake up the one or more
       flusher threads.
     - Flusher threads are page-based; they write back whole pages.
     - Older flusher threads implementation are known as "bdflush" and
       "pdflush".

CURIOSITIES
 - Physical memory can be directly accessed from user space by mapping /dev/mm






NODES AND ZONES
 - struct pglist_data (typedef pg_data_t) represents a memory bank chip called
   "node" in Linux. NUMA machines have multiple pg_data_t. UMA machines have a
   single pg_data_t.
 - Each node is divided into zones. Each zone is represented by a struct
   zone. Possible zone types are:
      - ZONE_DMA
      - ZONE_NORMAL
      - ZONE_HIGHMEM
 - Each physical page frame is described by a struct page. All structs are kept
   in a global mem_map array which is usually stored at the beginning of
   ZONE_NORMAL.
 - When not enough memory left, the kswapd daemon is woken up to start freeing
   memory. There are three watermarks that define the behaviour of the daemon:
   pages_high, pages_low and pages_min.
     - pages_high -> there are lots of free space. If the kswapd was running,
       it is stopped.
     - pages_low -> kswapd is waken up and stats freeing pages.
     - pages_min -> kswapd works in a synchronous faishon.
 - The  ZONE_PADDING(_pad1_) in struct zone is used to keep spinlocks in
   separate cache lines.
 - Each zone keeps a struct per_cpu_pageset (an array of two positions of type
   struct per_cpu_pages) which differentiates between hot and cold pages for
   the LRU algorithm.
 - The struct per_cpu_pages keeps a list of pages and a high and low watermark
   that determines when the set shoul be refilled or pages freed in bulk.
 - The struct page_state holds a number of acounting variables
PAGE TABLE STRUCTURE
 - Each task_struct (process) has a mm->pgd which contains the address of the
   process page table hierarchy.
 - The process mm->pgd is written into the cr3 register (on x86) to let the
   hardware know the current page table hierarchy. Writting to cr3 has de side
   effect of flushing the TLB.
 - mm->pgd points to a page frame which contains an array of type pmd_t with
   entries that point to the page middle directory pages. Each of this pmd_t
   contains an array of pte_t which actually point to page frames containing
   user data.
 - Each entry of time pgd_t, pmd_t and pte_t contain an 32 bit address (for
   x86). The page flags are stored in the PAGE_SHIFT (12) bits of the address.
   They are free because entries point to page aligned addresses. However, this
   is achitecture dependent. Flags can be found at
   arch/x86/include/asm/pgtable_types.h . Example of x86 flags are:
     - _PAGE_PRESENT -> Page is in memory adn not swapped out
     - _PAGE_RW -> Page can be written to
     - _PAGE_USER -> Set if page is accessible from userspace
     - _PAGE_DIRTY -> Page has been written
 - Important macros and functions:
     - #define PAGE_SHIFT 12
     - #define PAGE_SIZE  (1UL << PAGE_SHIFT)
     - #define PAGE_MASK  (~(PAGE_SHIFT-1))
     - #define PTRS_PER_PGD -> contains the number of entries for the PGD
     - pte_present() -> return whether page is present in memory
     - PAGE_ALIGN(addr) -> return the next page aligned to addr.
     - pgd_offset(mm, address) -> takes a process mm object and an address and
       returns the index in the page global directory of the relevant address.
       Equivalent function exists for PMD, PTE.
     - pgd_none() -> return 1 if entry does not exists.
     - pgd_clear() -> clears the corresponding page table entry
     - pgd_bad() -> check if page is valid (I don't understand how it works)
     - pte_read(), pte_mkread() pte_rdprotect() -> test,set,clear read
       permission. The equivalent exists for write and exec. On x86 there are
       no "exec" permissions on pages so it acts as a read.
     - pte_dirty(), pte_mkdirty(), pte_mkclean() -> test, check and set access bit.
     - pte_young(), pte_mkyoung(), pte_old() -> test, check and set diry bit.
     - mk_pte() -> takes a struct page and protection bits and returns a pte_t
       that needs to be inserted into the page table.
     - mk_pte_phys() -> the same as mk_pte but thakes a physical page address
       as a parameter.
     - pte_page(), pmd_page() -> returns the struct page which corresponds to
       the given PTE/PMD entry.
     - set_pte() -> set a pte_t returned by a function such as mk_pte()
     - pte_clear() ->  delete a pte_t entry from the page table.
     - ptep_get_and_clear() -> delete and return a pte_t entry from the page table.
     - pgd_alloc(), pmd_alloc(), pte_alloc(), *_free() -> allocate and free a
       page to store pgd, pmd and pte entries. These functions keep a LIFO
       cache of pages. If the cache is empty, pages are allocated using the
       physical page allocator.
  - The kernel currently supports 5-level page table which are named:
    PGD, P4D, PUD, PMD and PTE.
  - the mm->page_table_lock protectes the page table hierarchy structure.


TLB
  - Documentation at Documentation/cachetlb.txt
